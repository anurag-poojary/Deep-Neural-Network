{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08110942-17be-4fd9-ac92-3bf8e7de2498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Load the IMDB dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "max_len = 500  \n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Removed input_length argument\n",
    "model.add(Embedding(input_dim=10000, output_dim=128))  # Removed input_length\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Prepare new reviews for prediction\n",
    "new_reviews = [\n",
    "    \"The movie was amazing! I loved the acting and the plot was very engaging.\",\n",
    "    \"I hated this movie. It was too slow and the characters were boring.\"\n",
    "]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(new_reviews)\n",
    "new_reviews_sequences = tokenizer.texts_to_sequences(new_reviews)\n",
    "new_reviews_padded = pad_sequences(new_reviews_sequences, maxlen=max_len)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_reviews_padded)\n",
    "predicted_labels = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "# Output predictions\n",
    "for review, label in zip(new_reviews, predicted_labels):\n",
    "    sentiment = \"Positive\" if label == 1 else \"Negative\"\n",
    "    print(f\"Review: {review}\\nPredicted Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd8cd07-9ecd-403d-8af1-6a725cd41b52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 - 67s - 172ms/step - accuracy: 0.7887 - loss: 0.4255 - val_accuracy: 0.8754 - val_loss: 0.2992\n",
      "Epoch 2/5\n",
      "391/391 - 80s - 206ms/step - accuracy: 0.9022 - loss: 0.2453 - val_accuracy: 0.8775 - val_loss: 0.2920\n",
      "Epoch 3/5\n",
      "391/391 - 83s - 213ms/step - accuracy: 0.9357 - loss: 0.1713 - val_accuracy: 0.8680 - val_loss: 0.3556\n",
      "Epoch 4/5\n",
      "391/391 - 81s - 208ms/step - accuracy: 0.9582 - loss: 0.1161 - val_accuracy: 0.8661 - val_loss: 0.4025\n",
      "Test Loss: 0.2920, Test Accuracy: 0.8775\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the IMDB dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Set a reduced maximum sequence length\n",
    "max_len = 300\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# Create a tf.data dataset for efficient data loading\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1024).batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # You can adjust the number of LSTM units\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=5,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18488c-69ff-4c05-acfb-6c4fc024671c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
